{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69205f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074e26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datamodules import BaseDataModule\n",
    "from torchgeo.trainers import BaseTask\n",
    "from torchgeo.transforms import AugmentationSequential\n",
    "from torchmetrics import JaccardIndex, MetricCollection, Precision, Recall\n",
    "from tqdm import tqdm\n",
    "\n",
    "import kornia.augmentation as K\n",
    "\n",
    "from src.ftw.datamodules import preprocess, FTWDataModule\n",
    "from src.ftw.datasets import FTW\n",
    "from src.ftw.metrics import get_object_level_metrics\n",
    "from src.ftw.trainers import CustomSemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8399d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{0}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce02135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e9f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0, 0, 0, 0]) \n",
    "std = torch.tensor([3000, 3000, 3000, 3000])\n",
    "\n",
    "train_aug = AugmentationSequential(\n",
    "            K.Normalize(mean=mean, std=std),\n",
    "            K.RandomRotation(p=0.5, degrees=90),\n",
    "            K.RandomHorizontalFlip(p=0.5),\n",
    "            K.RandomVerticalFlip(p=0.5),\n",
    "            K.RandomSharpness(p=0.5),\n",
    "            data_keys=[\"image\", \"mask\"],\n",
    "        )\n",
    "\n",
    "aug = AugmentationSequential(\n",
    "            K.Normalize(mean=mean, std=std), data_keys=[\"image\", \"mask\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89365c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3 Class Masks, with Boundaries\n",
      "Temporal option:  windowB\n",
      "Selecting :  55779  samples\n",
      "Loading 3 Class Masks, with Boundaries\n",
      "Temporal option:  windowB\n",
      "Selecting :  6878  samples\n",
      "Loading 3 Class Masks, with Boundaries\n",
      "Temporal option:  windowB\n",
      "Selecting :  7805  samples\n"
     ]
    }
   ],
   "source": [
    "countries = [\"austria\", \"belgium\", \"brazil\", \"cambodia\", \"corsica\", \"croatia\", \"denmark\", \"estonia\", \"finland\", \n",
    "            \"france\", \"germany\", \"india\", \"kenya\", \"latvia\", \"lithuania\", \"luxembourg\", \"netherlands\", \"portugal\", \n",
    "            \"rwanda\", \"slovakia\", \"slovenia\", \"south_africa\", \"spain\", \"sweden\", \"vietnam\"]\n",
    "train_ds = FTW(\n",
    "        root=\"/home/airg/rbalogun/ftwfieldmapper/data/ftw_data\",\n",
    "        countries=countries,\n",
    "        split=\"train\",\n",
    "        transforms=train_aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\" , # \"windowA\", \"windowB\" , \"median\"\n",
    "    )\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=12)\n",
    "\n",
    "val_ds = FTW(\n",
    "        root=\"/home/airg/rbalogun/ftwfieldmapper/data/ftw_data\",\n",
    "        countries=countries,\n",
    "        split=\"val\",\n",
    "        transforms=aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\" \n",
    "    )\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=12)\n",
    "\n",
    "test_ds = FTW(\n",
    "        root=\"/home/airg/rbalogun/ftwfieldmapper/data/ftw_data\",\n",
    "        countries=countries,\n",
    "        split=\"test\",\n",
    "        transforms=aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\" \n",
    "    )\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8daec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricCollection([\n",
    "            JaccardIndex(task=\"multiclass\", average=\"none\", num_classes=3, ignore_index=3),\n",
    "            Precision(task=\"multiclass\", average=\"none\", num_classes=3, ignore_index=3),\n",
    "            Recall(task=\"multiclass\", average=\"none\", num_classes=3, ignore_index=3)\n",
    "        ]).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a251b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from src.ftw.datamodules import preprocess, FTW\n",
    "from src.lacuna.utils import make_reproducible\n",
    "from src.lacuna.compiler import ModelCompiler\n",
    "from src.lacuna.models import unet, unet_att_d\n",
    "from src.lacuna.evaluate import evaluate\n",
    "\n",
    "\n",
    "import kornia.augmentation as K\n",
    "from torchgeo.transforms import AugmentationSequential\n",
    "\n",
    "def run_segmentation_ftw(config_path, do_train=True, test_only=False, do_prediction=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set reproducibility\n",
    "    make_reproducible(seed=42)\n",
    "\n",
    "    # Load configuration\n",
    "    with open(config_path, \"r\") as file:\n",
    "        params = yaml.safe_load(file)\n",
    "\n",
    "    params_train = params[\"Train_Validate\"]\n",
    "\n",
    "    # Dataset loading\n",
    "    mean = torch.tensor([0, 0, 0, 0])\n",
    "    std = torch.tensor([3000, 3000, 3000, 3000])\n",
    "    countries = params_train[\"countries\"]\n",
    "\n",
    "    train_aug = AugmentationSequential(\n",
    "        K.Normalize(mean=mean, std=std),\n",
    "        K.RandomRotation(p=0.5, degrees=90),\n",
    "        K.RandomHorizontalFlip(p=0.5),\n",
    "        K.RandomVerticalFlip(p=0.5),\n",
    "        K.RandomSharpness(p=0.5),\n",
    "        data_keys=[\"image\", \"mask\"],\n",
    "    )\n",
    "\n",
    "    val_aug = AugmentationSequential(\n",
    "        K.Normalize(mean=mean, std=std),\n",
    "        data_keys=[\"image\", \"mask\"],\n",
    "    )\n",
    "\n",
    "    train_ds = FTW(\n",
    "        root=params_train[\"data_path\"],\n",
    "        countries=countries,\n",
    "        split=\"train\",\n",
    "        transforms=train_aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\",\n",
    "    )\n",
    "    val_ds = FTW(\n",
    "        root=params_train[\"data_path\"],\n",
    "        countries=countries,\n",
    "        split=\"val\",\n",
    "        transforms=val_aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\",\n",
    "    )\n",
    "    test_ds = FTW(\n",
    "        root=params_train[\"data_path\"],\n",
    "        countries=countries,\n",
    "        split=\"test\",\n",
    "        transforms=val_aug,\n",
    "        load_boundaries=True,\n",
    "        temporal_options=\"windowB\",\n",
    "    )\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=params_train[\"train_batch\"], shuffle=True, num_workers=12)\n",
    "    val_dl = torch.utils.data.DataLoader(val_ds, batch_size=params_train[\"validate_batch\"], shuffle=False, num_workers=12)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=params_train[\"validate_batch\"], shuffle=False, num_workers=12)\n",
    "\n",
    "    # Compile model\n",
    "\n",
    "    model = ModelCompiler(\n",
    "            model = eval(params_train['model'])( \n",
    "                    params_train['n_classes'],\n",
    "                    params_train['channels'],\n",
    "                    **params_train['model_kwargs']\n",
    "                    ),\n",
    "            working_dir=params_train[\"model_working_dir\"],\n",
    "            out_dir=params_train[\"model_out_dir\"],\n",
    "            buffer=params_train[\"buffer\"],\n",
    "            class_mapping=params_train[\"class_mapping\"],\n",
    "            gpu_devices=params_train.get(\"gpu_devices\", [0]),\n",
    "            use_sync_bn=params_train.get(\"use_sync_bn\", False),\n",
    "            model_init_type=params_train.get(\"model_init_type\", \"kaiming\"),\n",
    "            params_init=params_train.get(\"params_init\", None),\n",
    "            freeze_params=eval(params_train.get(\"freeze_params\", \"None\"))\n",
    "        )\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # If in full training mode\n",
    "    if do_train and not test_only:\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "            train_dataset=train_dl,\n",
    "            val_dataset=val_dl,\n",
    "            epochs=params_train[\"epoch\"],\n",
    "            optimizer_name=params_train[\"optimizer_name\"],\n",
    "            lr_init=params_train[\"learning_rate_init\"],\n",
    "            lr_policy=params_train[\"learning_rate_policy\"],\n",
    "            criterion=nn.CrossEntropyLoss(),\n",
    "            momentum=params_train.get(\"momentum\", 0.9),\n",
    "            checkpoint_interval=params_train.get(\"checkpoint_interval\", 5),\n",
    "            early_stopping_patience=params_train.get(\"early_stopping_patience\", 10),\n",
    "            min_delta=params_train.get(\"min_delta\", 0.001),\n",
    "            warmup_period=params_train.get(\"warmup_period\", 10),\n",
    "        )\n",
    "\n",
    "    if do_prediction:\n",
    "        raise NotImplementedError(\"Prediction module not adapted yet. Coming soon.\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"Final Evaluation...\")\n",
    "    model.accuracy_evaluation(test_dl, filename=\"final_metrics_ftw.csv\")\n",
    "    print(f\"Evaluation saved at: {os.path.join(model.working_dir, model.out_dir)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c32da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "configPath = \"./src/configs/config_lacuna.yaml\"\n",
    "\n",
    "with open(configPath, \"r\") as config:\n",
    "        params = yaml.safe_load(config)\n",
    "\n",
    "# parameters\n",
    "params_train = params['Train_Validate']\n",
    "params_test = params['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4faf322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Vanilla Model compiled successfully ---------\n",
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n"
     ]
    }
   ],
   "source": [
    "from src.lacuna.compiler import ModelCompiler\n",
    "from src.lacuna.models import unet_att_d\n",
    "\n",
    "model = ModelCompiler(\n",
    "        model = eval(params_train['model'])( \n",
    "                params_train['n_classes'],\n",
    "                params_train['channels'],\n",
    "                **params_train['model_kwargs']\n",
    "                ),\n",
    "        working_dir=params_train[\"model_working_dir\"],\n",
    "        out_dir=params_train[\"model_out_dir\"],\n",
    "        buffer=params_train[\"buffer\"],\n",
    "        class_mapping=params_train[\"class_mapping\"],\n",
    "        gpu_devices=params_train.get(\"gpu_devices\", [0]),\n",
    "        use_sync_bn=params_train.get(\"use_sync_bn\", False),\n",
    "        model_init_type=params_train.get(\"model_init_type\", \"kaiming\"),\n",
    "        params_init= None, #params_train.get(\"params_init\", None),\n",
    "        freeze_params=eval(params_train.get(\"freeze_params\", \"None\"))\n",
    "    )\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffca4b1-591a-44bb-9450-9671abccbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "# Define loss (Dice Loss + CrossEntropy Loss)\n",
    "class DiceCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight_dice=0.5, weight_ce=0.5):\n",
    "        super().__init__()\n",
    "        self.dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_ce = weight_ce\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        dice = self.dice_loss(preds, targets)\n",
    "        ce = self.ce_loss(preds, targets)\n",
    "        return self.weight_dice * dice + self.weight_ce * ce\n",
    "\n",
    "criterion = DiceCrossEntropyLoss()\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=params_train[\"learning_rate_init\"])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, verbose=True)\n",
    "\n",
    "# Paths\n",
    "num_epochs = params_train[\"epoch\"]\n",
    "early_stopping_patience = params_train.get(\"early_stopping_patience\", 10)\n",
    "checkpoint_dir = params_train.get(\"model_out_dir\", \"./checkpoints\")\n",
    "metrics_log_file = os.path.join(checkpoint_dir, \"training_metrics.csv\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Class Mapping for evaluation\n",
    "class_mapping = params_train[\"class_mapping\"]  # Must be a dict like {0: \"classA\", 1: \"classB\", ...}\n",
    "\n",
    "# Training\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "metrics_records = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n--- Epoch {epoch}/{num_epochs} ---\")\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, labels, mask in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        imgs, labels, mask = imgs.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, mask in tqdm(val_dataloader, desc=\"Validating\"):\n",
    "            imgs, labels, mask = imgs.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    val_loss /= len(val_dataloader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Evaluate using your Evaluator\n",
    "    eval_metrics = Evaluator(\n",
    "        model=model,\n",
    "        dataloader=val_dataloader,\n",
    "        num_classes=model.classes,\n",
    "        class_mapping=class_mapping,\n",
    "        device=device,\n",
    "        buffer=params_train.get('buffer', None),\n",
    "        out_name=os.path.join(checkpoint_dir, f\"epoch{epoch}_metrics.csv\")\n",
    "    )\n",
    "\n",
    "    epoch_metrics = {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"overall_accuracy\": eval_metrics[\"Overall Accuracy\"],\n",
    "        \"mean_accuracy\": eval_metrics[\"Mean Accuracy\"],\n",
    "        \"mean_iou\": eval_metrics[\"Mean IoU\"],\n",
    "        \"mean_precision\": eval_metrics[\"mean Precision\"],\n",
    "        \"mean_recall\": eval_metrics[\"mean Recall\"],\n",
    "        \"mean_f1_score\": eval_metrics[\"Mean F1 Score\"],\n",
    "    }\n",
    "    metrics_records.append(epoch_metrics)\n",
    "\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "        f\"OA: {eval_metrics['Overall Accuracy']:.4f} | mIoU: {eval_metrics['Mean IoU']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"best_model_epoch{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"  → New best model saved to {checkpoint_path}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"  → Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics_records)\n",
    "metrics_df.to_csv(metrics_log_file, index=False)\n",
    "print(f\"\\nAll training metrics saved to {metrics_log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62aa0a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (MulticlassJaccardIndex): MulticlassJaccardIndex()\n",
       "  (MulticlassPrecision): MulticlassPrecision()\n",
       "  (MulticlassRecall): MulticlassRecall()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba9f0de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m all_fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m all_fns \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdl\u001b[49m):\n\u001b[1;32m      7\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     masks \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dl' is not defined"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "all_tps = 0\n",
    "all_fps = 0\n",
    "all_fns = 0\n",
    "\n",
    "for batch in tqdm(dl):\n",
    "    images = batch[\"image\"].to(device)\n",
    "    masks = batch[\"mask\"].to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(images)\n",
    "\n",
    "        outputs = outputs.argmax(dim=1)\n",
    "\n",
    "        new_outputs = torch.zeros(outputs.shape[0], outputs.shape[1], outputs.shape[2], device=device)\n",
    "        new_outputs[outputs == 2] = 0  # Boundary pixels\n",
    "        new_outputs[outputs == 0] = 0  # Background pixels\n",
    "        new_outputs[outputs == 1] = 1  # Crop pixels\n",
    "        outputs = new_outputs\n",
    "\n",
    "        metrics.update(outputs, masks)\n",
    "        outputs = outputs.cpu().numpy().astype(np.uint8)\n",
    "        masks = masks.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            output = outputs[i]\n",
    "            mask = masks[i]\n",
    "            if postprocess:\n",
    "                post_processed_output = out.copy()\n",
    "                output = post_processed_output\n",
    "            tps, fps, fns = get_object_level_metrics(mask, output, iou_threshold=iou_threshold)\n",
    "            all_tps += tps\n",
    "            all_fps += fps\n",
    "            all_fns += fns\n",
    "\n",
    "    results = metrics.compute()\n",
    "    pixel_level_iou = results[\"MulticlassJaccardIndex\"][1].item()\n",
    "    pixel_level_precision = results[\"MulticlassPrecision\"][1].item()\n",
    "    pixel_level_recall = results[\"MulticlassRecall\"][1].item()\n",
    "\n",
    "    if all_tps + all_fps > 0:\n",
    "        object_precision = all_tps / (all_tps + all_fps)\n",
    "    else:\n",
    "        object_precision = float('nan')\n",
    "\n",
    "    if all_tps + all_fns > 0:\n",
    "        object_recall = all_tps / (all_tps + all_fns)\n",
    "    else:\n",
    "        object_recall = float('nan')\n",
    "\n",
    "    print(f\"Pixel level IoU: {pixel_level_iou:.4f}\")\n",
    "    print(f\"Pixel level precision: {pixel_level_precision:.4f}\")\n",
    "    print(f\"Pixel level recall: {pixel_level_recall:.4f}\")\n",
    "    print(f\"Object level precision: {object_precision:.4f}\")\n",
    "    print(f\"Object level recall: {object_recall:.4f}\")\n",
    "\n",
    "    if out is not None:\n",
    "        if not os.path.exists(out):\n",
    "            with open(out, \"w\") as f:\n",
    "                f.write(\"train_checkpoint,test_countries,pixel_level_iou,pixel_level_precision,pixel_level_recall,object_level_precision,object_level_recall\\n\")\n",
    "        with open(out, \"a\") as f:\n",
    "            f.write(f\"{model},{countries},{pixel_level_iou},{pixel_level_precision},{pixel_level_recall},{object_precision},{object_recall}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
