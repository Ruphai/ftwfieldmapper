{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1591d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a921ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights: is this the model weight for the stacked datasets? \n",
    "# \"ftw-3class-full_unet-efficientnetb3_rgbnir_1ba4e1bd.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3fb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.ftw.trainers import CustomSemanticSegmentationTask\n",
    "\n",
    "\n",
    "# model = CustomSemanticSegmentationTask(\n",
    "#         model = \"unet\",\n",
    "#         backbone = \"efficientnet-b3\",\n",
    "#         weights = True,\n",
    "#         in_channels = 4,\n",
    "#         num_classes = 3,\n",
    "#         num_filters = 3,\n",
    "#         loss  = \"ce\",\n",
    "#         class_weights  = [0.04, 0.08, 0.88], # read from config\n",
    "#         ignore_index = 3,\n",
    "#         lr = 1e-3,\n",
    "#         patience= 100,\n",
    "#         patch_weights = False,\n",
    "#         freeze_backbone = True,\n",
    "#         freeze_decoder = False,\n",
    "#     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ee8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import segmentation_models_pytorch as smp\n",
    "# import torch\n",
    "\n",
    "# model = smp.Unet(\n",
    "#     encoder_name=\"efficientnet-b3\",\n",
    "#     encoder_weights=None,\n",
    "#     in_channels=4,\n",
    "#     classes=3\n",
    "# )\n",
    "# # model.load_state_dict(torch.load(\"model_weights/ftw-3class-full_unet-efficientnetb3_rgbnir_1ba4e1bd.pth\", weights_only=True))\n",
    "# pretrained = torch.load(\"model_weights/ftw-3class-full_unet-efficientnetb3_rgbnir_1ba4e1bd.pth\")\n",
    "\n",
    "# # Remove first conv weights (usually 'encoder.conv_stem.0.weight')\n",
    "# pretrained = {k: v for k, v in pretrained.items() if not k.startswith('encoder.conv_stem.0')}\n",
    "\n",
    "# model.load_state_dict(pretrained, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ff3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['encoder._conv_stem.weight']\n",
      "Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"model_weights/ftw-3class-full_unet-efficientnetb3_rgbnir_1ba4e1bd.pth\")\n",
    "\n",
    "# Remove _conv_stem.weight\n",
    "checkpoint.pop(\"encoder._conv_stem.weight\", None)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b3\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=4,  # 4 channels\n",
    "    classes=3\n",
    ")\n",
    "\n",
    "# Load everything else\n",
    "missing, unexpected = model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "print(f\"Missing keys: {missing}\")\n",
    "print(f\"Unexpected keys: {unexpected}\")\n",
    "\n",
    "# Reinitialize first conv layer manually (if you want better initialization)\n",
    "with torch.no_grad():\n",
    "    nn.init.kaiming_normal_(model.encoder._conv_stem.weight, mode='fan_out', nonlinearity='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48a4fd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      4, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3-4): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6-7): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9-12): 4 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14-17): 4 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19-23): 5 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(520, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(304, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(104, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapter \n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "# old_conv = model.encoder._conv_stem\n",
    "\n",
    "# # Replace it with a new conv accepting 4 channels\n",
    "# new_conv = nn.Conv2d(\n",
    "#     in_channels=4,\n",
    "#     out_channels=old_conv.out_channels,\n",
    "#     kernel_size=old_conv.kernel_size,\n",
    "#     stride=old_conv.stride,\n",
    "#     padding=old_conv.padding,\n",
    "#     bias=old_conv.bias is not None,\n",
    "# )\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     new_conv.weight[:, :4, :, :] = old_conv.weight[:, :4, :, :]\n",
    "# model.encoder._conv_stem = new_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61527d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/airg/rbalogun/ftwfieldmapper\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9576879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "configPath = \"./src/configs/config_lacuna.yaml\"\n",
    "\n",
    "with open(configPath, \"r\") as config:\n",
    "        params = yaml.safe_load(config)\n",
    "\n",
    "# parameters\n",
    "params_train = params['Train_Validate']\n",
    "params_test = params['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d988af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset\n",
      "type: <class 'numpy.ndarray'> shape/len: (224, 224, 4)\n",
      "----------20241 samples loaded in train dataset-----------\n",
      "Total number of samples in train dataset: 20241\n",
      "Loading validation dataset\n",
      "type: <class 'numpy.ndarray'> shape/len: (224, 224, 4)\n",
      "----------6746 samples loaded in validate dataset-----------\n",
      "Total number of samples in validate dataset: 6746\n"
     ]
    }
   ],
   "source": [
    "# load lacuna datasets. \n",
    "from src.lacuna.datatorch import ImageData\n",
    "\n",
    "# Load data\n",
    "print('Loading training dataset')\n",
    "            \n",
    "train_dataset = ImageData(\n",
    "        data_path = params_train['data_path'],\n",
    "        log_dir = params_train['log_dir'], \n",
    "        catalog = pd.read_csv(params_train['train_csv_name']).reset_index(drop=True), \n",
    "        data_size = params_train['data_size'],\n",
    "        buffer = params_train['buffer'],\n",
    "        buffer_comp = params_train['buffer_comp'],\n",
    "        usage = \"train\", \n",
    "        img_path_cols = params_train['img_path_cols'], \n",
    "        label_path_col = params_train['label_path_col'], \n",
    "        label_group = params_train['label_group'], \n",
    "        apply_normalization = params_train['apply_normalization'],\n",
    "        normal_strategy = params_train['normal_strategy'],\n",
    "        stat_procedure = params_train['stat_procedure'],\n",
    "        global_stats = params_train['global_stats'],\n",
    "        catalog_index = params_train['catalog_index'],\n",
    "        trans = params_train['trans'],\n",
    "        parallel = params_train['parallel'],\n",
    "        scale_factor = params_train['scale_factor'],\n",
    "        crop_strategy = params_train['crop_strategy'],\n",
    "        rotation_degree = params_train['rotation_degree'],\n",
    "        sigma_range = params_train['sigma_range'],\n",
    "        br_range = params_train['br_range'],\n",
    "        contrast_range = params_train['contrast_range'],\n",
    "        bshift_gamma_range = params_train['bshift_gamma_range'],\n",
    "        patch_shift = params_train['patch_shift'],\n",
    "        downfactor = params_train['downfactor'],\n",
    "        clip_val = params_train['clip_val'],\n",
    "        nodata = params_train['nodata']\n",
    "        )\n",
    "    \n",
    "train_dataloader = DataLoader(\n",
    "                        train_dataset,\n",
    "                        batch_size=params_train[\"train_batch\"],\n",
    "                        shuffle=True\n",
    "                        )\n",
    "\n",
    "# Load data\n",
    "print('Loading validation dataset')\n",
    "\n",
    "val_dataset = ImageData(\n",
    "        data_path = params_train['data_path'],\n",
    "        log_dir = params_train['log_dir'], \n",
    "        catalog = pd.read_csv(params_train['train_csv_name']).reset_index(drop=True), \n",
    "        data_size = params_train['data_size'],\n",
    "        buffer = params_train['buffer'],\n",
    "        buffer_comp = params_train['buffer_comp'],\n",
    "        usage = \"validate\", \n",
    "        img_path_cols = params_train['img_path_cols'], \n",
    "        label_path_col = params_train['label_path_col'], \n",
    "        label_group = params_train['label_group'], \n",
    "        apply_normalization = params_train['apply_normalization'],\n",
    "        normal_strategy = params_train['normal_strategy'],\n",
    "        stat_procedure = params_train['stat_procedure'],\n",
    "        global_stats = params_train['global_stats'],\n",
    "        catalog_index = params_train['catalog_index'],\n",
    "        trans = params_train['trans'],\n",
    "        parallel = params_train['parallel'],\n",
    "        scale_factor = params_train['scale_factor'],\n",
    "        crop_strategy = params_train['crop_strategy'],\n",
    "        rotation_degree = params_train['rotation_degree'],\n",
    "        sigma_range = params_train['sigma_range'],\n",
    "        br_range = params_train['br_range'],\n",
    "        contrast_range = params_train['contrast_range'],\n",
    "        bshift_gamma_range = params_train['bshift_gamma_range'],\n",
    "        patch_shift = params_train['patch_shift'],\n",
    "        downfactor = params_train['downfactor'],\n",
    "        clip_val = params_train['clip_val'],\n",
    "        nodata = params_train['nodata']\n",
    "        )\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "                        val_dataset,\n",
    "                        batch_size=params_train[\"validate_batch\"],\n",
    "                        shuffle=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603b4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuning ftw model on lacuna datasets\n",
    "# load weights: is this the model weight for the stacked datasets? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airg/rbalogun/miniconda3/envs/ftw_fieldmapper/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/50 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 83/633 [03:59<24:58,  2.73s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from src.lacuna.evaluate import Evaluator\n",
    "from src.lacuna.datatorch import ImageData\n",
    "\n",
    "\n",
    "# Define loss (Dice Loss + CrossEntropy Loss)\n",
    "class DiceCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight_dice=0.5, weight_ce=0.5):\n",
    "        super().__init__()\n",
    "        self.dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_ce = weight_ce\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        dice = self.dice_loss(preds, targets)\n",
    "        ce = self.ce_loss(preds, targets)\n",
    "        return self.weight_dice * dice + self.weight_ce * ce\n",
    "\n",
    "criterion = DiceCrossEntropyLoss()\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=params_train[\"learning_rate_init\"])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, verbose=True)\n",
    "\n",
    "# Paths\n",
    "num_epochs = params_train[\"epoch\"]\n",
    "early_stopping_patience = params_train.get(\"early_stopping_patience\", 10)\n",
    "checkpoint_dir = params_train.get(\"model_out_dir\", \"./checkpoints\")\n",
    "metrics_log_file = os.path.join(checkpoint_dir, \"training_metrics.csv\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Class Mapping for evaluation\n",
    "class_mapping = params_train[\"class_mapping\"]  # Must be a dict like {0: \"classA\", 1: \"classB\", ...}\n",
    "\n",
    "# Training\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "metrics_records = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n--- Epoch {epoch}/{num_epochs} ---\")\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, labels, mask in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        imgs, labels, mask = imgs.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, mask in tqdm(val_dataloader, desc=\"Validating\"):\n",
    "            imgs, labels, mask = imgs.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    val_loss /= len(val_dataloader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Evaluate using your Evaluator\n",
    "    eval_metrics = Evaluator(\n",
    "        model=model,\n",
    "        dataloader=val_dataloader,\n",
    "        num_classes=model.classes,\n",
    "        class_mapping=class_mapping,\n",
    "        device=device,\n",
    "        buffer=params_train.get('buffer', None),\n",
    "        out_name=os.path.join(checkpoint_dir, f\"epoch{epoch}_metrics.csv\")\n",
    "    )\n",
    "\n",
    "    epoch_metrics = {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"overall_accuracy\": eval_metrics[\"Overall Accuracy\"],\n",
    "        \"mean_accuracy\": eval_metrics[\"Mean Accuracy\"],\n",
    "        \"mean_iou\": eval_metrics[\"Mean IoU\"],\n",
    "        \"mean_precision\": eval_metrics[\"mean Precision\"],\n",
    "        \"mean_recall\": eval_metrics[\"mean Recall\"],\n",
    "        \"mean_f1_score\": eval_metrics[\"Mean F1 Score\"],\n",
    "    }\n",
    "    metrics_records.append(epoch_metrics)\n",
    "\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "        f\"OA: {eval_metrics['Overall Accuracy']:.4f} | mIoU: {eval_metrics['Mean IoU']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"best_model_epoch{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"  → New best model saved to {checkpoint_path}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"  → Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics_records)\n",
    "metrics_df.to_csv(metrics_log_file, index=False)\n",
    "print(f\"\\nAll training metrics saved to {metrics_log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5a27cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 224, 224])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataloader.dataset[0][0].shape)\n",
    "\n",
    "# val_dataloader.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c6b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftw_fieldmapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
